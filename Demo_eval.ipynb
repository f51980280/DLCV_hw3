{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras_retinanet import models\n",
    "from keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from retina.utils import visualize_boxes\n",
    "\n",
    "MODEL_PATH = '/root/anaconda3/envs/hw3/retinanet-digit-detector/snapshots/resnet152_pascal_04.h5'\n",
    "\n",
    "def load_inference_model(model_path=os.path.join('snapshots', 'resnet.h5')):\n",
    "    model = models.load_model(model_path, backbone_name='resnet152')\n",
    "    model = models.convert_model(model)\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def post_process(boxes, original_img, preprocessed_img):\n",
    "    # post-processing\n",
    "    h, w, _ = preprocessed_img.shape\n",
    "    h2, w2, _ = original_img.shape\n",
    "    boxes[:, :, 0] = boxes[:, :, 0] / w * w2\n",
    "    boxes[:, :, 2] = boxes[:, :, 2] / w * w2\n",
    "    boxes[:, :, 1] = boxes[:, :, 1] / h * h2\n",
    "    boxes[:, :, 3] = boxes[:, :, 3] / h * h2\n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)])\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = load_inference_model(MODEL_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
